{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fc47261",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/__init__.py:1854\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m library\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m-> 1854\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations\n\u001b[1;32m   1856\u001b[0m \u001b[38;5;66;03m# Enable CUDA Sanitizer\u001b[39;00m\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTORCH_CUDA_SANITIZER\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_meta_registrations.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims_common\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SymBool, SymFloat, Tensor\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decomp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     _add_op_to_registry,\n\u001b[1;32m     11\u001b[0m     _convert_out_params,\n\u001b[1;32m     12\u001b[0m     global_decomposition_table,\n\u001b[1;32m     13\u001b[0m     meta_table,\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpOverload\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _prim_elementwise_meta, ELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_decomp/__init__.py:243\u001b[0m\n\u001b[1;32m    239\u001b[0m             decompositions\u001b[38;5;241m.\u001b[39mpop(op, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    242\u001b[0m \u001b[38;5;66;03m# populate the table\u001b[39;00m\n\u001b[0;32m--> 243\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decomp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecompositions\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_refs\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;66;03m# See NOTE [Core ATen Ops]\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# list was copied from torch/_inductor/decomposition.py\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# excluding decompositions that results in prim ops\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# Resulting opset of decomposition is core aten ops\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_decomp/decompositions.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable, cast, Iterable, List, Optional, Tuple, Union\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mprims\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims_common\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_prims/__init__.py:2997\u001b[0m\n\u001b[1;32m   2988\u001b[0m fft_c2r \u001b[38;5;241m=\u001b[39m _make_prim(\n\u001b[1;32m   2989\u001b[0m     schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfft_c2r(Tensor self, *, int[] dim, SymInt last_dim_size) -> Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2990\u001b[0m     meta\u001b[38;5;241m=\u001b[39m_fft_c2r_meta,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2993\u001b[0m     doc\u001b[38;5;241m=\u001b[39m_fft_c2r_doc,\n\u001b[1;32m   2994\u001b[0m )\n\u001b[1;32m   2996\u001b[0m register_rng_prims()\n\u001b[0;32m-> 2997\u001b[0m register_debug_prims()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_prims/debug_prims.py:29\u001b[0m, in \u001b[0;36mregister_debug_prims\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mregister_debug_prims\u001b[39m():\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;129m@custom_op\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdebugprims::load_tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_tensor\u001b[39m(  \u001b[38;5;66;03m# type: ignore[empty-body]\u001b[39;00m\n\u001b[1;32m     31\u001b[0m         name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     32\u001b[0m         size: Sequence[\u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m     33\u001b[0m         stride: Sequence[\u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m     35\u001b[0m         dtype: torch\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m     36\u001b[0m         device: torch\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[1;32m     37\u001b[0m     ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;129m@load_tensor\u001b[39m\u001b[38;5;241m.\u001b[39mimpl_factory()\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_tensor_factory\u001b[39m(name, size, stride, dtype, device):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_custom_op/impl.py:139\u001b[0m, in \u001b[0;36mcustom_op.<locals>.inner\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manual_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     validate_function_matches_schema(function_schema, func)\n\u001b[0;32m--> 139\u001b[0m lib \u001b[38;5;241m=\u001b[39m library\u001b[38;5;241m.\u001b[39mLibrary(ns, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFRAGMENT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    140\u001b[0m lib\u001b[38;5;241m.\u001b[39mdefine(schema_str)\n\u001b[1;32m    141\u001b[0m ophandle \u001b[38;5;241m=\u001b[39m find_ophandle_or_throw(ns, function_schema\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/library.py:61\u001b[0m, in \u001b[0;36mLibrary.__init__\u001b[0;34m(self, ns, kind, dispatch_key)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ns \u001b[38;5;129;01min\u001b[39;00m _reserved_namespaces \u001b[38;5;129;01mand\u001b[39;00m (kind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEF\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m kind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFRAGMENT\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(ns, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is a reserved namespace. Please try creating a library with another name.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m frame \u001b[38;5;241m=\u001b[39m traceback\u001b[38;5;241m.\u001b[39mextract_stack(limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     62\u001b[0m filename, lineno \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mfilename, frame\u001b[38;5;241m.\u001b[39mlineno\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm: Optional[Any] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_dispatch_library(kind, ns, dispatch_key, filename, lineno)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/traceback.py:231\u001b[0m, in \u001b[0;36mextract_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[0;32m--> 231\u001b[0m stack \u001b[38;5;241m=\u001b[39m StackSummary\u001b[38;5;241m.\u001b[39mextract(walk_stack(f), limit\u001b[38;5;241m=\u001b[39mlimit)\n\u001b[1;32m    232\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/traceback.py:393\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f, lineno \u001b[38;5;129;01min\u001b[39;00m frame_gen:\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m f, (lineno, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m klass\u001b[38;5;241m.\u001b[39m_extract_from_extended_frame_gen(\n\u001b[1;32m    394\u001b[0m     extended_frame_gen(), limit\u001b[38;5;241m=\u001b[39mlimit, lookup_lines\u001b[38;5;241m=\u001b[39mlookup_lines,\n\u001b[1;32m    395\u001b[0m     capture_locals\u001b[38;5;241m=\u001b[39mcapture_locals)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/traceback.py:436\u001b[0m, in \u001b[0;36mStackSummary._extract_from_extended_frame_gen\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[0;32m--> 436\u001b[0m         f\u001b[38;5;241m.\u001b[39mline\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/traceback.py:321\u001b[0m, in \u001b[0;36mFrameSummary.line\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineno \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_line \u001b[38;5;241m=\u001b[39m linecache\u001b[38;5;241m.\u001b[39mgetline(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineno)\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_line\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/linecache.py:30\u001b[0m, in \u001b[0;36mgetline\u001b[0;34m(filename, lineno, module_globals)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetline\u001b[39m(filename, lineno, module_globals\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     27\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a line for a Python source file from the cache.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m    Update the cache if it doesn't contain an entry for this file already.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m     lines \u001b[38;5;241m=\u001b[39m getlines(filename, module_globals)\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m lineno \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(lines):\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m lines[lineno \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/linecache.py:46\u001b[0m, in \u001b[0;36mgetlines\u001b[0;34m(filename, module_globals)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cache[filename][\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m updatecache(filename, module_globals)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mMemoryError\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m     clearcache()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/linecache.py:136\u001b[0m, in \u001b[0;36mupdatecache\u001b[0;34m(filename, module_globals)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tokenize\u001b[38;5;241m.\u001b[39mopen(fullname) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m    137\u001b[0m         lines \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m, \u001b[38;5;167;01mSyntaxError\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/tokenize.py:398\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    396\u001b[0m buffer \u001b[38;5;241m=\u001b[39m _builtin_open(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 398\u001b[0m     encoding, lines \u001b[38;5;241m=\u001b[39m detect_encoding(buffer\u001b[38;5;241m.\u001b[39mreadline)\n\u001b[1;32m    399\u001b[0m     buffer\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    400\u001b[0m     text \u001b[38;5;241m=\u001b[39m TextIOWrapper(buffer, encoding, line_buffering\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/tokenize.py:367\u001b[0m, in \u001b[0;36mdetect_encoding\u001b[0;34m(readline)\u001b[0m\n\u001b[1;32m    364\u001b[0m         encoding \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-sig\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m encoding\n\u001b[0;32m--> 367\u001b[0m first \u001b[38;5;241m=\u001b[39m read_or_stop()\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first\u001b[38;5;241m.\u001b[39mstartswith(BOM_UTF8):\n\u001b[1;32m    369\u001b[0m     bom_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/tokenize.py:325\u001b[0m, in \u001b[0;36mdetect_encoding.<locals>.read_or_stop\u001b[0;34m()\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_or_stop\u001b[39m():\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 325\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m readline()\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Define the neural network architecture\n",
    "class ScoringModel(nn.Module):\n",
    "    def __init__(self, num_inputs=26):  # Adjusted number of inputs\n",
    "        super(ScoringModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(num_inputs, 512)\n",
    "        self.layer2 = nn.Linear(512, 256)\n",
    "        self.layer3 = nn.Linear(256, 128)\n",
    "        self.layer4 = nn.Linear(128, 64)\n",
    "        self.layer5 = nn.Linear(64, 32)\n",
    "        self.output_layer = nn.Linear(32, 1)\n",
    "        self.leaky_relu = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.leaky_relu(self.layer1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.leaky_relu(self.layer2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.leaky_relu(self.layer3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.leaky_relu(self.layer4(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.leaky_relu(self.layer5(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        return x\n",
    "\n",
    "# Load and prepare the dataset\n",
    "file_path = 'goal_ticks.csv'\n",
    "\n",
    "# Define column names based on the provided structure\n",
    "column_names = [\n",
    "    \"kart_ID\", \"ball_X\", \"ball_Z\", \"ball_aim_X\", \"ball_aim_Z\", \"ball_node\", \"previous_X\", \"previous_Z\", \"ball_heading\",\n",
    "    \"ball_appr_goal\", \"dist_to_ball\", \"kart_X\", \"kart_Z\", \"vel_X\", \"vel_Z\", \"speed\", \"steer\", \"accel\", \"kart_node\", \n",
    "    \"target_encoded\", \"target_pos_X\", \"target_pos_Z\", \"kart0_sector\", \"kart1_sector\", \"kart0_X\", \"kart0_Z\", \"kart1_X\", \n",
    "    \"kart1_Z\", \"has_powerup\", \"goal\"\n",
    "]\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(file_path, header=None, names=column_names)\n",
    "\n",
    "# Drop the specified columns\n",
    "df = df.drop(columns=[\"target_encoded\", \"target_pos_X\", \"target_pos_Z\"])\n",
    "\n",
    "# Print the first few rows of the dataframe to check if it loaded correctly\n",
    "print(\"First few rows of the dataframe:\")\n",
    "print(df.head())\n",
    "\n",
    "# Print the shape of the dataframe\n",
    "print(\"Dataframe shape:\", df.shape)\n",
    "\n",
    "# Check for NaN values\n",
    "nan_info = df.isna().sum()\n",
    "print(\"NaN values in each column:\")\n",
    "print(nan_info)\n",
    "\n",
    "# Check if any column has more than 0 NaN values\n",
    "if nan_info.sum() > 0:\n",
    "    # Handle NaNs: Drop rows with NaNs\n",
    "    df = df.dropna()\n",
    "    print(\"Dataframe shape after dropping NaNs:\", df.shape)\n",
    "else:\n",
    "    print(\"No NaN values found in the dataframe.\")\n",
    "\n",
    "# Check for empty dataframe\n",
    "if df.empty:\n",
    "    raise ValueError(\"The dataframe is empty after dropping NaNs. Please check the CSV file.\")\n",
    "\n",
    "# Extract features and labels\n",
    "X = df.iloc[:, :-1].values  # All columns except the last one (goal)\n",
    "y = df['goal'].values  # The 'goal' column as binary\n",
    "\n",
    "# Print the shape of features and labels\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Labels shape:\", y.shape)\n",
    "\n",
    "# Check if the dataset is empty\n",
    "if X.shape[0] == 0:\n",
    "    raise ValueError(\"The dataset is empty. Please check the CSV file and ensure it contains valid data.\")\n",
    "\n",
    "# Normalize all features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Save the scaler parameters for later use\n",
    "scaler_params = {\n",
    "    \"mean\": scaler.mean_.tolist(),\n",
    "    \"scale\": scaler.scale_.tolist()\n",
    "}\n",
    "\n",
    "print(\"Scaler parameters:\")\n",
    "print(json.dumps(scaler_params, indent=4))\n",
    "\n",
    "with open('scaler_parameters.json', 'w') as f:\n",
    "    json.dump(scaler_params, f)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(1)  # Keeping the target as a 2D tensor for BCELoss\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# Prepare data loaders\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Initialize the model with 26 inputs\n",
    "model = ScoringModel(num_inputs=26)\n",
    "\n",
    "# Set up the loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training function\n",
    "def train_model(train_loader, model, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        if (epoch + 1) % 10 == 0:  # Print every 10 epochs\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}')\n",
    "\n",
    "# Validation function\n",
    "def validate_model(val_loader, model, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "    print(f'Validation Loss: {total_loss / len(val_loader):.4f}')\n",
    "\n",
    "# Train and validate the model\n",
    "train_model(train_loader, model, criterion, optimizer, 10)\n",
    "validate_model(val_loader, model, criterion)\n",
    "\n",
    "# Save the trained model for deployment\n",
    "model.eval()\n",
    "model_scripted = torch.jit.script(model)  # Export to TorchScript\n",
    "model_scripted.save(\"soccer_ai_model.pt\")  # Save\n",
    "\n",
    "# Print the weights of the output layer after training\n",
    "print(\"Weights of the output layer after training:\")\n",
    "print(model.output_layer.weight)\n",
    "print(\"Bias of the output layer after training:\")\n",
    "\n",
    "# Example output\n",
    "example_input = torch.rand(1, X_train.shape[1])  # Generate a random example input\n",
    "example_output = model(example_input)\n",
    "print(\"Example output:\", example_output.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8395ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "correlation_matrix = df.corr()\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
